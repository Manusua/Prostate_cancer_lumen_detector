{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3H1vOvK+V1C3SScEwePW2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/tema1/aprendizaje_supervisado_tema1_limpieza_datos_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"140px\" src=\"https://github.com/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/logos/logo_viu.png?raw=true\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1> Asignatura de Inteligencia Artificial</h1>\n",
        "\n",
        "\n",
        "La presente asignatura hace parte del máster oficial en Inteligencia Artificial, impartido en la Universidad Internacional de Valencia (VIU)."
      ],
      "metadata": {
        "id": "n8EL--64ia7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"contents\"></a></p>\n",
        "\n",
        "# Contenido Sesión 6: Introducción al Machine Learning:\n",
        "\n",
        "- <a href=\"#sklearn\">1. Introducción a Scikit-Learn</a><br>\n",
        "  - <a href=\"#sklearnG\">1.1. Generalidades</a><br>\n",
        "  - <a href=\"#sklearnT\">1.2. Tratamiento/limpieza de datos</a><br>\n",
        "    - <a href=\"#norm\">1.2.1. Normalización</a><br>\n",
        "    - <a href=\"#std\">1.2.2. Estandarización</a><br>\n",
        "- <a href=\"#deteccion_de_outliers\">2. Detección de outliers</a><br>\n",
        "  - <a href=\"#ellipticEnvelope\">2.1. Método de envolvente elíptica</a><br>\n",
        "  - <a href=\"#otros_metodos_outliers\">2.2. Otros métodos de detección de outliers</a><br>\n",
        "  - <a href=\"#boxplots\">2.3. Métodos de Boxplots/Cajas y Bigotes.</a><br>\n",
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "EsvFVNKkjuzW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_A9WFzM546Y"
      },
      "source": [
        "<p><a name=\"sklearn\"></a></p>\n",
        "\n",
        "# 1. Introducción a Scikit-Learn\n",
        "\n",
        "[Contenidos](#contents)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"sklearnG\"></a></p>\n",
        "\n",
        "## 1.1. Generalidades\n",
        "\n",
        "[Contenidos](#contents)\n"
      ],
      "metadata": {
        "id": "rEQluC4oPHba"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axPhkEXz5581"
      },
      "source": [
        "Hay varias bibliotecas de Python que proporcionan implementaciones sólidas de una variedad de algoritmos de ML. Una de las más conocidos es **Scikit-Learn**, un paquete que proporciona versiones eficientes de una gran cantidad de algoritmos comunes. Scikit-Learn se caracteriza por ser una API limpia, uniforme y optimizada, así como por una documentación en línea muy útil y completa. La API de Scikit-Learn está notablemente bien diseñada. Los principales principios de diseño son:\n",
        "\n",
        "* **Estimadores**: Cualquier objeto que pueda estimar algunos parámetros basados en un conjunto de datos se llama *estimador*. La estimación en sí misma se realiza mediante el método `fit()`, y solo toma un conjunto de datos como parámetro (o dos para algoritmos de aprendizaje supervisados; el segundo conjunto de datos contiene las etiquetas). Cualquier otro parámetro necesario para guiar el proceso de estimación se considera un hiperparámetro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9rY3e6M4fUC"
      },
      "source": [
        "* **Transformadores**: Algunos estimadores (como el imputer) también pueden transformar un conjunto de datos; Estos se llaman transformadores. Una vez más, la API es bastante simple: la transformación se realiza mediante el método `transform()` con el conjunto de datos para transformar como parámetro. Los transformadores también tienen un método conveniente llamado `fit_transform()` que es equivalente a llamar a `fit()` y luego aplicar `transform()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uphcWJo4j7x"
      },
      "source": [
        "* **Predictores**: Finalmente, algunos estimadores son capaces de hacer predicciones dado un conjunto de datos; Estos se conocen como predictores. Un predictor tiene un método `predict()` que toma un conjunto de datos de nuevas instancias y devuelve un conjunto de datos de predicciones correspondientes. También tiene un método `score()` que mide la calidad de las predicciones dado un conjunto de prueba. (El modelo `LinearRegression` que veremos más adelante es un ejemplo de un predictor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"sklearnT\"></a></p>\n",
        "\n",
        "## 1.2. Tratamiento/limpieza de datos\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "Oyk_HDgeIw8q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThYEc56n6AP9"
      },
      "source": [
        "\n",
        "\n",
        "En Machine Learning (ML), se trata de crear modelos a partir de datos, en donde estos debe ser presentados de forma adecuada según el algoritmo usado.\n",
        "\n",
        "Para los casos de algoritmos se basan en distancias, pesos asociados a características, etc, es necesario proceder a **normalizar** o **estandarizar** los datos. La *normalización* se lleva a cabo en aquellos algoritmos de machine learning que no se presupone una distribución de los datos. Por el contrario, la *estandarización* se debe llevar a cabo en aquellos casos en que los algoritmos de machine learning presuponen que los datos sigue una distribución normal.\n",
        "\n",
        "Los algoritmos de ML no funcionan bien cuando los atributos numéricos de entrada tienen escalas muy diferentes (o en algunos casos las entradas deben estar normalizadas/estandarizadas).\n",
        "\n",
        "---\n",
        "**¡IMPORTANTE!**\n",
        "\n",
        "Cuando se divide un conjunto de datos en `train`y `test`, se debe normalizar o estandarizar los datos usando el conjunto de `train`, y realizar la transformación sobre el grupo de `test` usando el `estimador` definido para el grupo de `train`.\n",
        "\n",
        "---\n",
        "\n",
        "Veamos como llevar a cabo estos dos métodos en python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keS9v4A2qiig"
      },
      "source": [
        "<p><a name=\"norm\"></a></p>\n",
        "\n",
        "### 1.2.1. Normalización de características\n",
        "\n",
        "[Contenidos](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYdSdabfqvxh"
      },
      "source": [
        "En la normalización, los datos sufren la siguiente transformación:\n",
        "\n",
        "$$ x'=\\frac{x-x_{min}}{x_{max}-x_{min}}.$$\n",
        "\n",
        "en donde, los valores finales de cada una de las características estarán definidos en el rango $[0,1]$.\n",
        "\n",
        "Veamos un ejemplo a continuación de como normalizar un conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hj6TDESrqByu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos.\n",
        "X_train = np.array([[ 1., -4.,  5.],\n",
        "                    [ 5.,  0.,  2.],\n",
        "                    [ 0.,  6., -3.]])\n",
        "\n",
        "print(X_train)"
      ],
      "metadata": {
        "id": "kJlQcZn-qDNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza de datos: normalización.\n",
        "normalizer = preprocessing.MinMaxScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "JOv8tCGXcMsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salida de resultados.\n",
        "print(X_train_norm)"
      ],
      "metadata": {
        "id": "B6ZxmRpIcbUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejemplo para ver que los resultados son iguales si aplicamos los métodos \"fit\" y \"transform\" por separado\n",
        "X_train_2 = np.copy(X_train)\n",
        "\n",
        "# Crea un objeto \"fitted_normalizer\" llamando al método \"fit\"\n",
        "f = normalizer.fit(X_train)\n",
        "\n",
        "# Aplica el objeto sobre los datos \"X_train_2\" para obtener \"X_train_norm_2\"\n",
        "X_train_norm_2 = f.transform(X_train)\n",
        "\n",
        "# Comprueba si \"X_train_norm\" y \"X_train_norm_2\" son iguales\n",
        "print(np.array_equiv(X_train_norm, X_train_norm_2))"
      ],
      "metadata": {
        "id": "cDl97hkVck6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio**"
      ],
      "metadata": {
        "id": "PXvR1hPZdvzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar un nuevo conjunto de datos de test (SOLO HAY QUE APLICAR EL MÉTODO \"transform\", NO EL \"fit\")\n",
        "X_test = np.array([[ 1., -3.,  2.],\n",
        "                    [ 3.,  0.,  0.],\n",
        "                    [ 0.,  4., -1.]])"
      ],
      "metadata": {
        "id": "5A7QLxRjd74z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"std\"></a></p>\n",
        "\n",
        "### 1.2.2. Estandarización\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "eNGWyEQKBYTx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQv2DNcOvmlv"
      },
      "source": [
        "En la estandarización, los datos sufren la siguiente transformación:\n",
        "\n",
        "$$x'=\\frac{x-\\bar x}{\\sigma}$$\n",
        "\n",
        "siendo\n",
        "\n",
        "- $\\bar x$ la media de los datos\n",
        "- $\\sigma$ la desviación típica/estandar de los datos\n",
        "\n",
        "Veamos como llevar a cabo este proceso en python."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rnU8GUAre7Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos.\n",
        "X_train = np.array([[ 1., -1.,  2.],\n",
        "                    [ 2.,  0.,  0.],\n",
        "                    [ 0.,  1., -1.]])"
      ],
      "metadata": {
        "id": "wlm-LhHke8hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio**"
      ],
      "metadata": {
        "id": "5gVLyiKpfF3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limpieza de datos: estandarización.\n",
        "standardizer = preprocessing.StandardScaler()\n",
        "\n",
        "# Estandarizamos los datos de entrenamiento\n",
        "# ???"
      ],
      "metadata": {
        "id": "qtpeTDO7fDJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio**"
      ],
      "metadata": {
        "id": "jMO0q5ZAfSN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_2 = np.array([[ 1., -1.,  2.],\n",
        "                    [ 2.,  0.,  0.],\n",
        "                    [ 0.,  1., -1.]])"
      ],
      "metadata": {
        "id": "_FnwWn8ufId6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicamos los métodos \"fit\" y \"transform\" por separado\n",
        "# ???\n",
        "# ???"
      ],
      "metadata": {
        "id": "Q_-BtMIRfYlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprobar si las matrices estandarizadas son iguales\n",
        "# ???"
      ],
      "metadata": {
        "id": "uX1jQ1SLfa82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"deteccion_de_outliers\"></a></p>\n",
        "\n",
        "# 2. Detección de outliers\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "XrJfQ_AIh2sG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La detección de outliers tiene como fin la eliminación de aquellas instacias de un dataset que represantan valores anómalos. Si incluimos dichos valores anómalos, podremos incurrir en el entrenamiento de modelos que incluyan los casos atípicos como \"normales\" (esta frase necesita discusión y ser razonada en profundidad).\n",
        "\n",
        "A continuación veremos los siguiente métodos para la detección de outliers:\n",
        "\n",
        "- Método de envolvente elíptica\n",
        "- Otros métodos de detección de outliers\n",
        "- Método de boxplots/cajas y bigotes"
      ],
      "metadata": {
        "id": "60mc0O8JJRYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OzANlV7Bh8aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos.\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/ssanchezgoe/viu_aprendizaje_supervisado/main/datasets/outliers.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "ESxD54n8h_du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"ellipticEnvelope\"></a></p>\n",
        "\n",
        "## 2.1. Método de envolvente elíptica\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "pkf9kMecicfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "algorithm = EllipticEnvelope(support_fraction=None, contamination=0.25, random_state=42)\n",
        "outlier_method = algorithm.fit(df)\n",
        "\n",
        "# Aplicamos el método de detección de outliers entrenado sobre nuesto dataset\n",
        "df_outliers = outlier_method.predict(df)\n",
        "print(df_outliers)\n",
        "\n",
        "# Determinar la posición de los outliers\n",
        "pos_outliers = np.where(df_outliers==-1)[0]\n",
        "print('\\nOutliers en la posición: \\n', pos_outliers)\n",
        "\n",
        "# Determinar el número de outliers\n",
        "print('\\nNúmero de outliers: \\n', len(pos_outliers))"
      ],
      "metadata": {
        "id": "bOb8UFmxiWpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##**Ejercicio**: Crear una función que, a partir de un dataframe \"df\" y un algoritmo \"algorithm\", devuelva la matriz y la posición de los outliers.\n",
        "\n",
        "def find_outliers(df, algorithm):\n",
        "\n",
        "  outlier_method = algorithm.fit(df)\n",
        "  df_outliers = outlier_method.predict(df)\n",
        "\n",
        "  pos_outliers = np.where(df_outliers==-1)[0]\n",
        "  print('\\nOutliers en la posición: \\n', pos_outliers)\n",
        "\n",
        "  # Determinar el número de outliers\n",
        "  print('\\nNúmero de outliers: \\n', len(pos_outliers))\n",
        "\n",
        "  return df_outliers, pos_outliers\n"
      ],
      "metadata": {
        "id": "URGuKjG4jpVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"otros_metodos_outliers\"></a></p>\n",
        "\n",
        "## 2.2. Otros métodos de detección de outliers\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "hckO-BWnq7Em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existen métodos similares al de la envolvente que pueden ser consultados en el link de [algoritmos de detección de outliers de Sklearn](https://scikit-learn.org/stable/modules/outlier_detection.html)."
      ],
      "metadata": {
        "id": "0Nxay5fRrUnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##**Ejercicio:** En base al ejercicio anterior, lleve a cabo una detección de outlier el dataframe \"df\" mediante cualquier de los métodos definidos en Sklean (IsolationForest, LocalOutlierFactor o OneClassSVM).\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "IF = IsolationForest()\n",
        "# OC_SVM = ???\n",
        "# LOF = ???\n",
        "\n",
        "df_outliers, pos_outliers = find_outliers(df, IF)\n",
        "print(len(pos_outliers))\n"
      ],
      "metadata": {
        "id": "P4HGhLjWq3Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"boxplots\"></a></p>\n",
        "\n",
        "## 2.3. Método de Boxplots/Cajas y Bigotes\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "xbpm6KucE32p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los box plot representan gráficas en las que se pueden analizar varias características de un conjunto de datos como:\n",
        "\n",
        "<ol>\n",
        "    <li> La distribución de los datos.</li>\n",
        "    <li> Asimetría.</li>\n",
        "    <li> Los puntos aislados.</li>\n",
        "</ol>\n",
        "\n",
        "En la siguiente gráfica se muestran las diferentes partes de una gráfica de caja:\n",
        "\n",
        "<img src=\"https://i.ibb.co/6tkRtg0/Captura-de-pantalla-2019-08-22-19-01-17.png\" style=\"width:250px;height:300px;\" alt=\"Captura-de-pantalla-2019-08-20-22-39-39\" border=\"0\"></a>\n",
        "\n",
        "En esta gráfica, podemos identificar las siguiente cantidades:\n",
        "\n",
        "- 1. Mediana\n",
        "- 2. Cuartil superior $P_{75}$\n",
        "- 3. Cuartil inferior $P_{25}$\n",
        "- 4. Rango intercuartil $IQR=P_{75}-P_{25}$\n",
        "- 5. Extremo superior\n",
        "\n",
        "$$UE = \\begin{cases}\n",
        "P_{\\text{75}}+1.5\\times IQR = UP & \\text{si } UP < \\text{max(Data)} \\\\\n",
        "\\text{max(Data)}       & \\text{si } UP \\ge \\text{max(Data)}\n",
        "\\end{cases}$$\n",
        "\n",
        "- 6. Extremo inferior\n",
        "\n",
        "$$LE= \\begin{cases}\n",
        "P_{\\text{25}}-1.5\\times IQR = LO & \\text{si } LO > \\text{min(Data)}\n",
        "\\\\\n",
        "\\text{min(Data)} & \\text{si } LO \\le \\text{min(Data)}\n",
        "\\end{cases}$$"
      ],
      "metadata": {
        "id": "08KlCGZYE5fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libraries & dataset\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# set a grey background (use sns.set_theme() if seaborn version 0.11.0 or above)\n",
        "sns.set(style=\"darkgrid\")\n",
        "x = np.random.randn(200)\n",
        "\n",
        "# creating a figure composed of two matplotlib.Axes objects (ax_box and ax_hist)\n",
        "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
        "\n",
        "# assigning a graph to each ax\n",
        "sns.boxplot(x, orient=\"h\", ax=ax_box)\n",
        "sns.histplot(x,  ax=ax_hist)\n",
        "\n",
        "# Remove x axis name for the boxplot\n",
        "ax_box.set(xlabel='')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5rH0zo_5E5FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Código de detección de outlieres mediante boxplots**"
      ],
      "metadata": {
        "id": "fwoVkS2NIQj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionamos el atributo que vamos a medir\n",
        "a = df['a']\n",
        "\n",
        "# Seleccionamos los umbrales a partir de los cuales vamos a considerar outliers\n",
        "Q1 = stats.scoreatpercentile(a, 25)\n",
        "Q3 = stats.scoreatpercentile(a, 75)\n",
        "RIC = Q3 - Q1\n",
        "li = Q1 - 1.5*RIC #xmin\n",
        "ls = Q3 + 1.5*RIC #xmax\n",
        "\n",
        "# Observamos los límites inferior y superior\n",
        "print('limite inferior: ', li)\n",
        "print('limite superior: ', ls)\n",
        "\n",
        "# Buscamos la posición de los outliers\n",
        "pos_i = np.where(a<li)[0]\n",
        "pos_s = np.where(a>ls)[0]\n",
        "pos_outliers = np.concatenate((pos_i, pos_s))\n",
        "print('Posición de outliers: ', pos_outliers)\n",
        "print('Número de outliers: ', len(pos_outliers))\n",
        "\n",
        "# Dibujamos el diagrama de caja y bigotes\n",
        "prop = plt.boxplot(a)\n",
        "plt.boxplot(a)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ebKzCK7OFvtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir una función que, dada una columna de un dataframe, devuelva la posición de los outliers según el método box plot\n",
        "def find_limits_BP(variable):\n",
        "\n",
        "    # ???\n",
        "\n",
        "    return pos_outliers"
      ],
      "metadata": {
        "id": "MeW3iGZVIedL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos un bucle for que estime los valores outliers de cada atributo\n",
        "pos_outliers = []\n",
        "for i in df.columns:\n",
        "    variable =  # ???] # Atributo i\n",
        "    pos_out = # ??? # Buscamos los outliers en esa variable con la función que hemos creado\n",
        "    pos_out = np.expand_dims(pos_out, axis=1) # Extpandimos las dimensiones\n",
        "    pos_outliers.append(pos_out) # Lo añadimos en una lista"
      ],
      "metadata": {
        "id": "9XvNTxD0IhXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenamos todas las posiciones de outliers\n",
        "po = np.vstack(pos_outliers)\n",
        "\n",
        "# Vemos las posiciones de todos los outliers\n",
        "pos_out = np.unique(po)\n",
        "print('Posiciones de outliers totales: ', pos_out)\n",
        "\n",
        "# Observamos el número de outliers\n",
        "print('Numero de outliers totales: ', len(pos_out))"
      ],
      "metadata": {
        "id": "ahugMeU7Ijy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJ6jIikA6RQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}