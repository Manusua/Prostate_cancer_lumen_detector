{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYnnQmYNKzkU/nWcP8xyv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/tema2/aprendizaje_supervisado_tema2_validacion_modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"140px\" src=\"https://github.com/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/logos/logo_viu.png?raw=true\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1> Asignatura de Inteligencia Artificial</h1>\n",
        "\n",
        "\n",
        "La presente asignatura hace parte del máster oficial en Inteligencia Artificial, impartido en la Universidad Internacional de Valencia (VIU)."
      ],
      "metadata": {
        "id": "k7_Du4yrWIWd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78qd66pPmDP_"
      },
      "source": [
        "<p><a name=\"contents\"></a></p>\n",
        "\n",
        "# Contenido\n",
        "\n",
        "- <a href=\"#val\">1 Validación</a><br>\n",
        " - <a href=\"#hold_out_cross_val\">1.1 Validación hold-out y validación cruzada</a><br>\n",
        " - <a href=\"#bstrap\">1.2 Bootstrapping</a><br>\n",
        " - <a href=\"#mod_val\">1.3 Over/under-fitting</a><br>\n",
        " - <a href=\"#val_cur\">1.4 Curvas de validación</a><br>\n",
        " - <a href=\"#lea_cur\">1.5 Curvas de aprendizaje</a><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90sFT8GJmDQC"
      },
      "source": [
        "<p><a name=\"msel\"></a></p>\n",
        "\n",
        "# 1. Validación:\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La elección del modelo y de los hiperparámetros es tal vez la parte más importante para darle un uso efectivo a estas herramientas y técnicas. Para tomar una decisión acertada respecto a qué modelo e hiperparámetros elegir, necesitamos una forma de validar que estos se ajusten bien a los datos.\n",
        "\n",
        "Este proceso inicia por una correcta partición de los datos; a continuación estudiaremos tres formas comunes de llevar a cabo la esta tarea:\n",
        "\n",
        "- Validación hold-out\n",
        "- Validación cruzada\n",
        "- Bootstrapping"
      ],
      "metadata": {
        "id": "BgAfD5JiYLXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"hold_out_cross_val\"></a></p>\n",
        "\n",
        "## 1.1 Validación hold-Out y validación cruzada.\n",
        "\n",
        "[[Contenidos]](#contents)"
      ],
      "metadata": {
        "id": "qYUKY8XbmS9y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j44mkR6cVQH9"
      },
      "source": [
        "Existen dos aproximaciones estándar para la evaluación de los modelos, creadas con el fin de probar la capacidad de generalización de estos y su intependencia respecto a la partición de los datos:\n",
        "\n",
        "- **Validación Hold-out**: en la que se realiza una partición de los datos en entrenamiento (train) y prueba (test).\n",
        "\n",
        "- **Validación cruzada**: en la que se hacen $n$ iteraciones, dividiendo el conjunto de datos en $n$ subconjuntos. Cada subconjunto de datos se use como un conjunto de entrenamiento y como un conjunto de validación. En la siguiente figura ilustra el proceso:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbRFxTFUVSgz"
      },
      "source": [
        "![picture](https://www.analyticslane.com/wp-content/uploads/2018/07/validacion_cruzada.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnKkRnJZVUkR"
      },
      "source": [
        "En esta ilustración, se dividen los datose n tres grupos, y usamos cada uno de ellos para evaluar el ajuste del modelo (test) en los otros 2/3 de los datos para su entrenamiento (train). Como salida tendremos tres puntajes de desempeño del modelo, que podríamos combinar (por ejemplo, tomando la media) para obtener una mejor medición del rendimiento del modelo global.\n",
        "\n",
        "\n",
        "Veamos un ejemplo de estos métodos de partición de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpncjAqFVXZL"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga de datos\n",
        "\n",
        "X, y = load_diabetes(return_X_y = True)\n",
        "X_data, y_data = X[0:100], y[0:100]"
      ],
      "metadata": {
        "id": "YOdnkmYMbx8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Partición para validación hold-out\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state = 0)\n",
        "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "lQ2qhvoXcx2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Partición para validación cruzada\n",
        "kf = KFold(3, shuffle = True) # partición aleatoria\n",
        "#kf = KFold(4, random_state = 2, shuffle = True) # partición no aleatoria\n",
        "# enumerate splits\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_data)):\n",
        "  print(f\"Fold {i}:\")\n",
        "  print(f\"  Train: index={train_index} \\n len {len(train_index)}\\n\")\n",
        "  print(f\"  Test:  index={test_index} \\n len {len(test_index)} \\n\")"
      ],
      "metadata": {
        "id": "WU53Pc65b5Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urJe1EfoVW_z"
      },
      "source": [
        "La repetición de la validación en diferentes subconjuntos de datos nos da una idea aún mejor del rendimiento del algoritmo. El esquema que acabamos de ver, que se implementa por defecto, se conoce como k-fold VC. Scikit-Learn implementa una serie de esquemas de VC que son útiles en situaciones particulares; Estos se implementan a través de iteradores en el módulo [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html). También puede visitar la documentación del parámetro [scoring](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) para ver las métricas usadas para las diferentes tareas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o86-c1-OfIYm"
      },
      "source": [
        "<p><a name=\"bstrap\"></a></p>\n",
        "\n",
        "## 1.2 Bootstraping\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3MFrkXzfVpE"
      },
      "source": [
        "También es posible hacer la validación del modelo haciendo un particionado de datos con re-sampleo. De esta forma, se puede llevar a cabo estadísticas con niveles de confianza, algo que no puede realizarse en otros casos.\n",
        "\n",
        "La partición del dataset se lleva a cabo mediante los siguientes pasos:\n",
        "\n",
        "*   Se determina el tamaño de la muestra por el usuario.\n",
        "*   Se selecciona iterativamente una instancia de la muestra, mientras el número de instancias en la muestra sea menor al tamaño determinado por el usuario.\n",
        "* Todos los datos que no hayan sido elegidos para la muestra de entrenamiento serán elegidos como muestra de test. A éstos datos se les conoce generalmente como **out of bags** (fuera de la bolsa).\n",
        "\n",
        "En la selección es posible que una instancia sea elegida más de una vez para hacer parte de la muestra de entrenamieto, sin embargo jamás habrán instancias en ambas muestras (train, test).\n",
        "\n",
        "Así es posible generar estadísticas de la robustes de nuestro algoritmo sobre datos nunca vistos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcKc76n-2-Wi"
      },
      "source": [
        "\n",
        "En la siguiente figura se ilustran las tres técnicas de partición de datos vistas:\n",
        "\n",
        "![picture](https://d3ansictanv2wj.cloudfront.net/emlm_0302-6a388b903f6e1e04c95e718940eff039.png)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM545xkY7I8n"
      },
      "source": [
        "from sklearn.utils import resample #metodo de muestreo con remplazo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "#crear la muestra de bootstrap\n",
        "boot = resample(data, replace=True, n_samples=5, random_state=3)\n",
        "print('Bootstrap:',boot)\n",
        "# out of bag\n",
        "oob = [x for x in data if x not in boot]\n",
        "print('OOB:',oob)"
      ],
      "metadata": {
        "id": "9oHS9drhmGK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuCQTRzY5JV8"
      },
      "source": [
        "Validemos con éste método sobre un modelo lineal de los creados en clases pasadas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j05WeTAF5Smm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "df=pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/FuelConsumptionCo2.csv')\n",
        "df.dropna(inplace=True)\n",
        "data= df[['ENGINESIZE','CO2EMISSIONS']].values\n",
        "\n",
        "MAE = []\n",
        "n_rep = 40\n",
        "\n",
        "for i in range(n_rep):\n",
        "  boot = resample(data, replace=True, n_samples=int(len(data)/2))\n",
        "  oob = np.array([x for x in data if x.tolist() not in boot.tolist()])\n",
        "\n",
        "  X_train = boot[:,0].reshape(-1,1)\n",
        "  y_train = boot[:,1]\n",
        "  X_test = oob[:,0].reshape(-1,1)\n",
        "  y_test = oob[:,1]\n",
        "  #entrenamos el modelo\n",
        "  elastic = ElasticNet(alpha=0.01,l1_ratio=1)\n",
        "  elastic.fit(X_train,y_train)\n",
        "  y_pred = elastic.predict(X_test)\n",
        "  mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "  MAE.append(mae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp9RwCqq8knx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(MAE)\n",
        "plt.title(r'Distribución del MAE')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Law1Dsa9IW7C"
      },
      "source": [
        "media = np.mean(MAE)\n",
        "dstd = np.std(MAE)\n",
        "print('Error MAE:',media,'+/-',dstd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkE_VNAAIpnB"
      },
      "source": [
        "Como vemos es posible generar estadísticas sobre nuestros errores y su distribución, además de su intervalo de confianza, así podemos hacer afirmaciones con mayor certeza dobre la robustez de nuetro modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"mod_val\"></a></p>\n",
        "\n",
        "## 1.3 Over/under-fitting.\n",
        "\n",
        "[[Contenidos]](#contents)"
      ],
      "metadata": {
        "id": "s281jq3YmZLp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALNLqDG4VgIR"
      },
      "source": [
        "Introduzcamos ambos conceptos mediante la siguiente ilustración de dos modelos con problemáticas distintas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umBF3NniVwZJ"
      },
      "source": [
        "![picture](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-bias-variance.png?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAkUxcHHVy8e"
      },
      "source": [
        "Está claro que ninguno de estos modelos se ajusta bien a los datos, pero fallan de diferentes maneras:\n",
        "\n",
        "- El modelo de la izquierda intenta ajustar una línea recta a los datos. Debido a que los datos son intrínsecamente más complejos, el modelo de línea recta nunca podrá describir bien este conjunto de datos. Decimos entonces que el modelo tiene un sesgo alto o underfitting.\n",
        "\n",
        "- El modelo de la derecha ajusta los datos mediante un polinomio de grado superior. El ajuste del modelo tiene suficiente flexibilidad para explicar adecuadamente las características de los datos de entrenamiento, pero no a los datos de validación o test. Decimos entonces que el modelo tiene una alta varianza u overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M577M8alV0sg"
      },
      "source": [
        "![picture](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-bias-variance-2.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LIWV5a4V3Cx"
      },
      "source": [
        "Si imaginamos que tenemos alguna capacidad para ajustar la complejidad del modelo, esperaríamos que el puntaje de entrenamiento y el puntaje de prueba se comporten como se ilustra en la siguiente figura\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR96GxleV5C5"
      },
      "source": [
        "![picture](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.03-validation-curve.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIyw-abyV8MH"
      },
      "source": [
        "* El puntaje de entrenamiento siempre es más alto que el puntaje de prueba.\n",
        "* Para una complejidad de modelo muy baja (un modelo con alto sesgo), los datos de entrenamiento no son adecuados, lo que significa que el modelo es un mal predictor tanto para los datos de entrenamiento como para cualquier dato no visto previamente.\n",
        "* Para una complejidad de modelo muy alta (un modelo con alta varianza), los datos de entrenamiento están sobreajustados, lo que significa que el modelo predice muy bien los datos de entrenamiento, pero falla para cualquier dato no visto previamente.\n",
        "* Para algún valor intermedio, la curva de validación tiene un máximo. Este nivel de complejidad indica una compensación adecuada entre sesgo y varianza."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSnyFd6cV-u3"
      },
      "source": [
        "<p><a name=\"val_cur\"></a></p>\n",
        "\n",
        "## 1.4 Curvas de validación\n",
        "\n",
        "[[Contenidos]](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos un ejemplo de uso de validación cruzada para calcular la curva de validación para un modelo de regresión polinomial. Utilizaremos un *pipeline* que contenga la operación de preprocesamiento polinomial (`PolynomialFeatures`) y la regresión lineal (`LinearRegression`)"
      ],
      "metadata": {
        "id": "2w4_hKp6p03v"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwCpeDm-WBxe"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def PolynomialRegression(degree=2, **kwargs):\n",
        "    return make_pipeline(PolynomialFeatures(degree),\n",
        "                         LinearRegression(**kwargs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4i42KCgWEcY"
      },
      "source": [
        "Generemos unos datos para ajustar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpKyXsOVWGNJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def datos(N, err=1.0, rseed=1):\n",
        "    # generar datos de forma aleatoria\n",
        "    rng = np.random.RandomState(rseed)\n",
        "    X = rng.rand(N, 1) ** 2\n",
        "    y = 10 - 1. / (X.ravel() + 0.1)\n",
        "    if err > 0:\n",
        "        y += err * rng.randn(N)\n",
        "    return X, y\n",
        "\n",
        "X, y = datos(40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlHVLy6DWJR4"
      },
      "source": [
        "Ahora podemos visualizar nuestros datos, junto con ajustes polinómicos de varios grados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GfPZCEAWLu2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
        "\n",
        "plt.scatter(X.ravel(), y, color='black')\n",
        "axis = plt.axis()\n",
        "for degree in [1, 3, 5]:\n",
        "    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)\n",
        "    plt.plot(X_test.ravel(), y_test, label='Grado={0}'.format(degree))\n",
        "plt.xlim(-0.1, 1.0)\n",
        "plt.ylim(-2, 12)\n",
        "plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zG_ZX_8WOZ3"
      },
      "source": [
        "Lo que controla la complejidad del modelo en este caso es el grado del polinomio. ¿qué grado de polinomio proporciona una compensación adecuada entre el sesgo (subajuste) y la varianza (sobreajuste)?\n",
        "\n",
        "Podemos visualizar la curva de validación para este modelo y datos particulares; Esto se puede hacer directamente usando la función validation_curve provista por Scikit-Learn. Dado un modelo, datos, nombre de parámetro y un rango para explorar, esta función calculará automáticamente tanto el puntaje de entrenamiento como el puntaje de validación en todo el rango"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF1wfDHUWQZY"
      },
      "source": [
        "from sklearn.model_selection import validation_curve\n",
        "degree = np.arange(0, 21)\n",
        "train_score, val_score = validation_curve(PolynomialRegression(), X, y, param_name = 'polynomialfeatures__degree', param_range = degree, cv=7)\n",
        "\n",
        "plt.plot(degree, np.median(train_score, 1), color='blue', label='Puntaje de entrenamiento')\n",
        "plt.plot(degree, np.median(val_score, 1), color='red', label='Puntaje de validación')\n",
        "plt.legend(loc='best')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel('Grado')\n",
        "plt.ylabel('Puntaje');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTLy_6dWT12"
      },
      "source": [
        "Esto muestra con precisión el comportamiento cualitativo que esperamos: el puntaje de entrenamiento es en todas partes más alto que el puntaje de validación; el puntaje de entrenamiento mejora monotónicamente con una mayor complejidad del modelo; y la puntuación de validación alcanza un máximo antes de caerse a medida que el modelo se sobreajusta.\n",
        "\n",
        "A partir de la curva de validación, podemos deducir que el equilibrio óptimo entre sesgo y varianza se encuentra para un polinomio de tercer orden:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwH_W5hsWV_L"
      },
      "source": [
        "plt.scatter(X.ravel(), y)\n",
        "lim = plt.axis()\n",
        "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n",
        "plt.plot(X_test.ravel(), y_test);\n",
        "plt.axis(lim);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sINdMBYKWYiC"
      },
      "source": [
        "<p><a name=\"lea_cur\"></a></p>\n",
        "\n",
        "## 1.5 Curvas de aprendizaje\n",
        "\n",
        "[[Contenidos]](#contents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un aspecto importante de la complejidad del modelo es que el modelo óptimo generalmente dependerá del tamaño de los datos de entrenamiento. Por ejemplo, generemos un nuevo conjunto de datos con un factor de cinco puntos más:"
      ],
      "metadata": {
        "id": "JBZp0LKdp87a"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U20Hjl9DWanW"
      },
      "source": [
        "X2, y2 = datos(200)\n",
        "plt.scatter(X2.ravel(), y2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1adaocaHWdHR"
      },
      "source": [
        "Trazemos la curva de validación"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHdtphPZWe71"
      },
      "source": [
        "degree = np.arange(21)\n",
        "train_score2, val_score2 = validation_curve(PolynomialRegression(), X2, y2, param_name = 'polynomialfeatures__degree', param_range = degree, cv=7)\n",
        "\n",
        "plt.plot(degree, np.median(train_score2, 1), color='blue', label='training score')\n",
        "plt.plot(degree, np.median(val_score2, 1), color='red', label='validation score')\n",
        "plt.plot(degree, np.median(train_score, 1), color='blue', alpha=0.3, linestyle='dashed')\n",
        "plt.plot(degree, np.median(val_score, 1), color='red', alpha=0.3, linestyle='dashed')\n",
        "plt.legend(loc='lower center')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel('degree')\n",
        "plt.ylabel('score');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVcnruAuWiEI"
      },
      "source": [
        "Las líneas continuas muestran los nuevos resultados, mientras que las líneas discontinuas más débiles muestran los resultados del conjunto de datos anterior más pequeño. A partir de la curva de validación, es claro que el conjunto de datos más grande puede admitir un modelo mucho más complicado: el pico se da alrededor de un grado 6, pero incluso un modelo de grado 20 no está sobreajustando los datos: los puntajes de entrenamiento y de validación están muy cercanos. Por lo tanto, vemos que el comportamiento de la curva de validación no tiene una sino dos entradas importantes: la complejidad del modelo y el número de puntos de entrenamiento.\n",
        "\n",
        "Scikit-Learn ofrece una práctica utilidad para calcular tales curvas de aprendizaje de sus modelos; Aquí calcularemos una curva de aprendizaje para nuestro conjunto de datos original con un modelo polinomial de segundo orden y un polinomio de noveno orden:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgyBzjlzWkAG"
      },
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)\n",
        "\n",
        "for i, degree in enumerate([2, 9]):\n",
        "    N, train_lc, val_lc = learning_curve(PolynomialRegression(degree),\n",
        "                                         X, y, cv=7,\n",
        "                                         train_sizes=np.linspace(0.3, 1, 25))\n",
        "\n",
        "    ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='Puntaje de entrenamiento')\n",
        "    ax[i].plot(N, np.mean(val_lc, 1), color='red', label='Puntaje de validación')\n",
        "    ax[i].hlines(np.mean([train_lc[-1], val_lc[-1]]), N[0], N[-1],\n",
        "                 color='gray', linestyle='dashed')\n",
        "\n",
        "    ax[i].set_ylim(0, 1)\n",
        "    ax[i].set_xlim(N[0], N[-1])\n",
        "    ax[i].set_xlabel('Tamaño de los datos de entrenamiento')\n",
        "    ax[i].set_ylabel('Puntaje')\n",
        "    ax[i].set_title('Grado = {0}'.format(degree), size=14)\n",
        "    ax[i].legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk7DfKa6WmvP"
      },
      "source": [
        "Este es un diagnóstico valioso, porque nos da una descripción visual de cómo nuestro modelo responde al aumento de los datos de entrenamiento. En particular, cuando la curva de aprendizaje ya ha convergido (es decir, cuando las curvas de entrenamiento y validación ya están cercanas entre sí), ¡agregar más datos de entrenamiento no mejorará significativamente el ajuste! Esta situación se ve en el panel izquierdo, con la curva de aprendizaje para el modelo de grado 2.\n",
        "\n",
        "Trazar una curva de aprendizaje para nuestra elección particular de modelo y conjunto de datos puede ayudarnos a tomar una decisión sobre cómo avanzar para mejorar el análisis."
      ]
    }
  ]
}