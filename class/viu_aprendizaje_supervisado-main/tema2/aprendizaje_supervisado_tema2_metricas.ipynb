{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtX9wvoAClNO2n2Ln5Wfrh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/tema2/aprendizaje_supervisado_tema2_metricas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"140px\" src=\"https://github.com/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/logos/logo_viu.png?raw=true\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1> Asignatura de Inteligencia Artificial</h1>\n",
        "\n",
        "\n",
        "La presente asignatura hace parte del máster oficial en Inteligencia Artificial, impartido en la Universidad Internacional de Valencia (VIU)."
      ],
      "metadata": {
        "id": "v5arberOybxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"contents\"></a></p>\n",
        "\n",
        "# Contenido\n",
        "\n",
        "- <a href=\"#metricas\">1. Métricas</a><br>\n",
        "  - <a href=\"#metricas_regresion\">1.1 Métricas de regresión</a><br>\n",
        "  - <a href=\"#metricas_clasificacion\">1.2 Métricas de clasificación </a><br>\n",
        "    - <a href=\"#tipos_error\">1.2.1 Tipos de error</a><br>\n",
        "    - <a href=\"#datos_no_balanceados\">1.2.2 Datos no balanceados<a><br>\n",
        "    - <a href=\"#matriz_de_confusion\">1.2.3 Matriz de confusión<a><br>\n",
        "    - <a href=\"#todas_las_metricas\">1.2.4 Precisión, exhaustividad, exactitud y demás métricas.<a><br>\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "V2igoSWpK6DD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"metricas\"></a></p>\n",
        "\n",
        "# 1. Métricas\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "Es0F6ym182vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de iniciar el estudio de los algorítmos de machine learning en aprendizaje supervisado, se debe comprender los tipos de métricas en función del tipo de la variable objetivo $y$ a predecir. En este sentido, existen dos grandes grupos de métricas que se estudian en esta sesión:\n",
        "\n",
        "* **Métricas para regresión**: en donde la variable objetivo es de tipo númerico y continua, y las métricas tienen como eje común la distancia entre el valor real y el valor predicho: $y_i - \\hat{y}_i$\n",
        "* **Métricas para clasificación:** en donde la variable objetivo es de tipo categórica, y las métricas tienen como eje común un conteo de las clases predichas de forma correcta o incorrecta respecto al total de muestras (o bien por clase, o bien en conjunto).\n",
        "\n",
        "En cualquier caso, las métricas son puntajes numéricos.\n",
        "\n",
        "Veamos a continuación cada una de estas métricas."
      ],
      "metadata": {
        "id": "dqzsi8WX8mSC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksuZ7R8U6Alp"
      },
      "source": [
        "<p><a name=\"metricas_regresion\"></a></p>\n",
        "\n",
        "## 1.1 Métricas de regresión\n",
        "\n",
        "[Contenidos](#contents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvpxqubig4lK"
      },
      "source": [
        "**Regresión lineal simple**\n",
        "\n",
        "Empecemos por comprender de qué se trata la regresión lineal. Recordemos que la ecuación de un línea recta esta dada por:\n",
        "\n",
        "$$y = m*x+b$$\n",
        "\n",
        "donde $y$ es la variable dependiente, $x$ la independiente y a $m$ y $b$ las llamamos pendientes e intercepto.\n",
        "\n",
        "En el ambito del ML solemos reescribir la ecuación como\n",
        "\n",
        "$$y=w_0+w_1x$$\n",
        "\n",
        "siendo $w_0$ y $w_1$ llamados los \"parámetros del modelo\", en lo que se conoce como **regresión lineal simple**.\n",
        "\n",
        "El objetivo mediante un conjunto de datos como el que se presenta a continuación, sería el de encontrar los mejores parámetros  $w_0$ y $w_1$ que representan a los datos mediante una recta.\n",
        "\n",
        "![Imagen tomada de medium.com](https://miro.medium.com/max/642/1*xxxqZtZExBJoxmYKIY-waw.png)\n",
        "\n",
        "Existen varios algoritmos para resolver ésta tarea, el más simple es usar el algorítmo de mínimos cuadrados.\n",
        "\n",
        "El algoritmo encuentra los parámetros que minimizan la el error cuadrado conjunto (la suma) entre nuestras predicciones y los valores reales.\n",
        "\n",
        "![Imagen tomada de /www.jmp.com](https://www.jmp.com/en_hk/statistics-knowledge-portal/what-is-multiple-regression/fitting-multiple-regression-model/_jcr_content/par/styledcontainer_2069/par/lightbox_4130/lightboxImage.img.png/1548704005203.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regresión lineal múltiple**\n",
        "\n",
        "A diferencia de la regresión lineal simple, en donde se ajusta una recta a un conjunto de puntos, en la regresión lineal múltiple se ajusta un hiperplano a un conjunto de datos mediante la siguiente ecuación:\n",
        "\n",
        "$$y=w_0+w_1x_1+w_2x_2+...+w_nx_n$$\n",
        "\n",
        "En la siguiente figura, se ilustra un caso de un ajuste lineal múltiple de un plano representado por dos variables independientes $x_i$ a un conjunto de datos.\n",
        "\n",
        "![Regresión lineal múltiple](https://github.com/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/logos/multiple_LR.png?raw=true)"
      ],
      "metadata": {
        "id": "30HKclOj207u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGFxtafDqn9z"
      },
      "source": [
        "\n",
        "En cualquiera de los casos (regresión lineal simple o múltiple), necesitamos una medida de qué tan bien (o mal) el modelo se ajusta a los datos de entrenamiento. Esta medida de evaluación (función de costo) es el error calculado entre la recta/hiperplano generada/o $\\hat{y}$ a los puntos reales. El entrenamiento del modelo será entonces encontrar los valores de $w_i$ que minimicen dicha función de costo.\n",
        "\n",
        "Entre las métricas más populares encontramos:\n",
        "\n",
        "* Error medio absoluto (MAE)\n",
        "\n",
        "$$\\text{MAE} = \\frac{1}{m}\\sum_{i=1}^{m}|\\hat{y}_i -y_i|$$\n",
        "\n",
        "* Error absoluto percentual medio (MAPE)\n",
        "\n",
        "$$\\text{MAPE} = \\frac{1}{m}\\sum_{i=1}^{m} \\frac{|\\hat{y}_i -y_i|}{\\text{max}(\\epsilon,|y_i|)}$$\n",
        "\n",
        "\n",
        "* Error cuadrático medio (MSE)\n",
        "\n",
        "$$\\text{MSE}=\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{y}_i -y_i\\right)^2$$\n",
        "\n",
        "* Raíz del error cuadrático medio (RMSE)\n",
        "\n",
        "$$\\text{RMSE}=\\sqrt{\\frac{1}{m}\\sum_{i=1}^{m}\\left(\\hat{y}({\\bf x})_i -y_i\\right)^2}$$\n",
        "\n",
        "Estas métricas las podemos obtener del módulo [metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) de sklearn. Apliquémoslas al modelo lineal simple estudiado en la sesión anterior:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.2. Ejercicio Guiado"
      ],
      "metadata": {
        "id": "9ZU9BNL4FQkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "xIV746M8FQNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar y explorar los datos\n",
        "datos = fetch_california_housing()\n",
        "pprint(datos)\n",
        "print(np.shape(datos.data))"
      ],
      "metadata": {
        "id": "rG4nuYT0HRtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraer la matriz de datos \"X\" y la variable target \"y\"\n",
        "# Cargar 2000 datos"
      ],
      "metadata": {
        "id": "lZuOyGlgFzyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir 0.2 test y fijar semilla aleatoria"
      ],
      "metadata": {
        "id": "EtC4UWSCI5UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estandarización de los datos de entrenamiento y test"
      ],
      "metadata": {
        "id": "GqAbURUQV5DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas de evaluación.\n",
        "metricas = {\n",
        "  'MAE': 'neg_mean_absolute_error',\n",
        "  'MSE': 'neg_mean_squared_error',\n",
        "  'RMSE': make_scorer(lambda y, y_pred:\n",
        "                      sqrt(mean_squared_error(y, y_pred)),\n",
        "                      greater_is_better=False),\n",
        "  'MAPE': make_scorer(lambda y, y_pred:\n",
        "                      np.mean(np.abs((y - y_pred) / y)) * 100,\n",
        "                      greater_is_better=False)}"
      ],
      "metadata": {
        "id": "JRysaVfXWigt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un algoritmo SVM de regresión\n",
        "algorithm = SVR(C=1, gamma='auto',  kernel='rbf')"
      ],
      "metadata": {
        "id": "gM1BqKv-k-1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validación y evaluación del modelo.\n",
        "# en \"cv = KFold(n_splits=5)\" se hace un cross-validation INTERNO!!\n",
        "# results = ???\n",
        "# Presentación de los resultados de la evaluación.\n",
        "# pprint(results)"
      ],
      "metadata": {
        "id": "gAvsQY3LmFFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un algoritmo SVM de regresión candidato"
      ],
      "metadata": {
        "id": "A-teaCLupOdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAE en el conjunto de test"
      ],
      "metadata": {
        "id": "jFVrRIB5tryJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# También podemos extraer las predicciones para cuánto difieren los valores predichos de los reales"
      ],
      "metadata": {
        "id": "izEfox74v7Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafica de realidad -vs- prediccion.\n",
        "def grafica_real_vs_pred(y_true, y_pred, metricas, algoritmo):\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.scatter(y_true, y_pred, edgecolors=(0, 0, 0))\n",
        "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
        "    ax.set_xlabel('Valor real de la clase')\n",
        "    ax.set_ylabel('Predicción')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "W4gcAUENwCpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafica y_pred y_true"
      ],
      "metadata": {
        "id": "ZwbSpTFdwD_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento cross_val_score"
      ],
      "metadata": {
        "id": "0WH5DFFSOxDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"metricas_clasificacion\"></a></p>\n",
        "\n",
        "## 1.1 Métricas de clasificación\n",
        "\n",
        "[Contenidos](#contents)\n"
      ],
      "metadata": {
        "id": "DoAbSUpZGndW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzSujHsuUbq1"
      },
      "source": [
        "Las métricas de clasificación tienen como fin dar un puntaje para la compresión de los modelos en función de su clasificación de las clases.\n",
        "\n",
        "Empezaremos estudiando las métricas definidas en la **clasificación binaria** en donde solo existen dos clases:\n",
        "\n",
        "- Clase positiva o clase 1.\n",
        "- Clase negativa, clase 0, o clase -1.\n",
        "\n",
        "Las métricas derivadas de la clasificación binaria, pueden extenderse a la clasificación multiclase (donde se tiene más de una clase)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"tipos_error\"></a></p>\n",
        "\n",
        "### 1.2.1 Tipos de error\n",
        "\n",
        "[Contenidos](#contents)\n"
      ],
      "metadata": {
        "id": "DPbBI92mNo4A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9tRxWngU6SQ"
      },
      "source": [
        "\n",
        "Imaginemos una aplicación para detectar de forma temprana el cáncer mediante una prueba automatizada. Si la prueba es negativa, se supondrá que el paciente está sano, mientras que si la prueba es positiva, el paciente se someterá a una evaluación adicional. Aquí, llamaremos a una prueba positiva (una indicación de cáncer) la clase positiva, y una prueba negativa a la clase negativa. No podemos suponer que nuestro modelo siempre funcionará perfectamente; este cometerá errores. Para cualquier aplicación, debemos preguntarnos cuáles son las consecuencias de estos errores en el mundo real.\n",
        "\n",
        "Un posible error es que un paciente sano se clasifique como positivo, lo que llevaría a pruebas adicionales. Esto conlleva algunos costos y un inconveniente para el paciente. Una predicción positiva incorrecta se llama **falso positivo**. El otro posible error es que un paciente enfermo se clasifique como negativo, por lo que no recibirá más pruebas ni tratamiento. El cáncer no diagnosticado podría conducir a problemas de salud graves e incluso podría ser fatal. Un error de este tipo (una predicción negativa incorrecta) se llama **falso negativo**.\n",
        "\n",
        "Por el contrario, existen aquellos casos en en que un algoritmo de ML puede clasificar correctamente las muestras positivas, que se conoce como **True positives**, o las muestras negativas, que se conoce como **True negatives**.Una métrica que resultaría lógica definir a partir de estos conceptos, sería la metrica de exactitud o accuracy:\n",
        "\n",
        "$$\\text{Accuracy} = \\frac{TP+TN}{P+N}$$\n",
        "\n",
        "No obstante, esta métrica puede quedarse corta a la hora de identificar si el modelo es más sensible a la detección de clases positivas o negativas. Para ello, es necesario definir más métricas. Empecémos por ilustrar entonces, en qué caso la métrica de accuracy nos puede dar una percepción incorrecta del desempeño de un algoritmo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"datos_no_balanceados\"></a></p>\n",
        "\n",
        "### 1.2.2 Datos no balanceados\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "RWwtBV4lN6HD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVB8iPokai-d"
      },
      "source": [
        "\n",
        "\n",
        "Los conjuntos de datos en los que una clase es mucho más frecuente que la otra a menudo se denominan conjuntos de datos no balanceados. En realidad, los datos no balanceados son la norma, y es raro que los eventos de interés tengan una frecuencia igual o incluso similar en los datos.\n",
        "\n",
        "Para ilustrar, crearemos un conjunto de datos desequilibrado 9:1 a partir del conjunto de datos [digits](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html), clasificando el dígito 9 contra las otras nueve clases:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyH-fZdlU9x5"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#cargamos el dataset y separamoslos datos de entrenamiento y la variable objetivo\n",
        "digits = load_digits()\n",
        "\n",
        "X = digits.data\n",
        "y = digits.target == 9\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "\n",
        "#mostramos el dígito 9\n",
        "plt.figure(1, figsize=(3, 3))\n",
        "plt.imshow(digits.images[9], cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5042CkSgVA-S"
      },
      "source": [
        "Podemos usar [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) para predecir siempre la clase mayoritaria (\"no nueve\") para ver cuál desinformativa puede ser la *accuracy*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLO9FRCeVDI_"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
        "\n",
        "pred_most_frequent = dummy_majority.predict(X_test)\n",
        "\n",
        "print(\"Etiqueta predicha única: {}\".format(np.unique(pred_most_frequent)))\n",
        "print(\"Puntaje: {:.2f}\".format(dummy_majority.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6w-ZPWTVFVn"
      },
      "source": [
        "Comparemos esto con el uso de un clasificador real"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH6Qcm2oVHIa"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(gamma=\"auto\").fit(X_train,y_train)\n",
        "\n",
        "pred_svm = svm.predict(X_test)\n",
        "\n",
        "print(\"Puntaje: {:.2f}\".format(svm.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOmJpOqbVKB3"
      },
      "source": [
        "En ambos casos obtenemos el mismo resultado. Esto podría indicar que algo está mal con la forma en que usamos SVC, o que la accuracy de hecho no es una buena medida. Evaluemos con otro modelo y esta vez, utilicemos el DummyClassifier de manera que produzca una salida aleatoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co1IC1j1VLxR"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "dummy = DummyClassifier().fit(X_train, y_train)\n",
        "pred_dummy = dummy.predict(X_test)\n",
        "print(\"Puntaje Dummy: {:.2f}\".format(dummy.score(X_test, y_test)))\n",
        "\n",
        "logreg = LogisticRegression(C=0.1, solver=\"liblinear\").fit(X_train, y_train)\n",
        "pred_logreg = logreg.predict(X_test)\n",
        "print(\"Puntaje LogReg: {:.2f}\".format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pQ6UwVIVNyL"
      },
      "source": [
        "El clasificador Dummy es claramente el peor (según la accuracy), mientras que LogisticRegression produce muy buenos resultados. Sin embargo, incluso el clasificador aleatorio produce más del 80% de precisión. Esto hace que sea muy difícil juzgar cuál de estos resultados es realmente útil. El problema aquí es que la accuracy es una medida inadecuada para cuantificar el rendimiento predictivo en este escenario no balanceado, por lo que necesitamos métricas alternativas."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"matriz_de_confusion\"></a></p>\n",
        "\n",
        "### 1.2.3 Matriz de confusión\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "67TnLGY2QYeO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFSpFZNGa1-8"
      },
      "source": [
        "Una de las formas más completas de representar el resultado de evaluar la clasificación binaria es usar matrices de confusión. Inspeccionemos las predicciones de LogisticRegression de la sección anterior usando la función `confusion_matrix`. Ya almacenamos las predicciones sobre el conjunto de prueba en `pred_logreg`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9kjOCQDVTgW"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion = confusion_matrix(y_test, pred_logreg)\n",
        "print(\"Confusion matrix:\\n{}\".format(confusion))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utQq5QabVVkh"
      },
      "source": [
        "La salida de confusion_matrix es una matriz de dos por dos, donde las filas corresponden a las clases verdaderas y las columnas corresponden a las clases predichas. Cada entrada cuenta con qué frecuencia una muestra que pertenece a la clase correspondiente a la fila (aquí, \"no nueve\" y \"nueve\") se clasificó como la clase correspondiente a la columna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09V-VPzEVX1g"
      },
      "source": [
        "!pip install mglearn;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_flFoLZVaTA"
      },
      "source": [
        "import mglearn\n",
        "\n",
        "mglearn.plots.plot_confusion_matrix_illustration()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v995taaUVc0H"
      },
      "source": [
        "Las entradas en la diagonal principal de la matriz de confusión corresponden a las clasificaciones correctas, mientras que otras entradas nos dicen cuántas muestras de una clase se clasificaron erróneamente como otra clase.\n",
        "\n",
        "Si declaramos \"un nueve\" como la clase positiva, podemos relacionar las entradas de la matriz de confusión con los términos falso positivo y falso negativo que presentamos anteriormente. Llamamos a las muestras clasificadas correctamente que pertenecen a los positivos verdaderos de clase positiva y a las muestras clasificadas correctamente que pertenecen a los negativos verdaderos de clase negativa. Estos términos generalmente se abrevian FP, FN, TP y TN y conducen a la siguiente interpretación para la matriz de confusión"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWkSnnqIVekr"
      },
      "source": [
        "mglearn.plots.plot_binary_confusion_matrix()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjW1z5C9VhG0"
      },
      "source": [
        "Ahora usemos la matriz de confusión para comparar los modelos que ajustamos anteriormente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQjFFVIaVi3B"
      },
      "source": [
        "print(\"Clase más frecuente:\")\n",
        "print(confusion_matrix(y_test, pred_most_frequent))\n",
        "print(\"\\nmodelo Dummy:\")\n",
        "print(confusion_matrix(y_test, pred_dummy))\n",
        "print(\"\\nSVM:\")\n",
        "print(confusion_matrix(y_test, pred_svm))\n",
        "print(\"\\nLogistic Regression\")\n",
        "print(confusion_matrix(y_test, pred_logreg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03S1lJjAVmCM"
      },
      "source": [
        "Mirando la matriz de confusión, es bastante claro que algo está mal con `pred_most_frequent` y `SVM`, porque siempre predicen la misma clase. `pred_dummy`, por otro lado, tiene un número muy pequeño de positivos verdaderos(5), particularmente en comparación con el número de falsos negativos y falsos positivos: hay muchos más falsos negativos que verdaderos negativos. Vemos que solo LR tiene un mejor rendimiento en todos los aspectos: tiene más positivos verdaderos y negativos verdaderos mientras que tiene menos falsos positivos y falsos negativos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p><a name=\"todas_las_metricas\"></a></p>\n",
        "\n",
        "### 1.2.4 Precisión, exhaustividad, exactitud y demás métricas.\n",
        "\n",
        "[Contenidos](#contents)"
      ],
      "metadata": {
        "id": "CRFx89-sQyKO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5xqQEg8VowN"
      },
      "source": [
        "Inspeccionar la matriz de confusión total es una tarea dificil, y aunque obtuvimos mucha información al observar todos los aspectos de la matriz, el proceso fue muy manual y cualitativo. Hay varias otras formas de resumir la matriz de confusión, siendo las más comunes la **precisión** y la **exhaustividad**. La precisión mide cuántas de las muestras predichas como positivas son realmente positivas:\n",
        "\n",
        "$$\\text{Precisión} = \\frac{TP}{TP + FP}$$\n",
        "\n",
        "La **precisión** se utiliza como una métrica de rendimiento cuando el objetivo es limitar el número de falsos positivos.\n",
        "\n",
        "La **exhaustividad**, por otro lado, mide cuántas de las muestras positivas son capturadas por las predicciones positivas:\n",
        "\n",
        "$$\\text{Exhaustividad} = \\frac{TP}{TP + FN}$$\n",
        "\n",
        "La exhaustividad se utiliza como métrica de rendimiento cuando necesitamos identificar todas las muestras positivas; es decir, cuando es importante evitar falsos negativos.\n",
        "\n",
        "Con frecuencia hay tensión entre precisión y exhaustividad. Esto quiere decir que, al mejorar la precisión, generalmente se reduce la exhaustividad, y viceversa. Por lo tanto, si bien la precisión y la exhaustividad son medidas muy importantes, mirar solo una de ellas no proporcionará una imagen completa del problema. Una forma de resumirlos es el *puntaje f* o la *medida f*, que es la media armónica entre precisión y exhaustividad.\n",
        "\n",
        "$$f = 2  \\frac{\\text{Precisión}*\\text{Exhaustividad}}{\\text{Precisión}+\\text{Exhaustividad}}$$\n",
        "\n",
        "Como tiene en cuenta la precisión y la exhaustividad, puede ser una mejor medida que la *accuracy* en los conjuntos de datos de clasificación binaria no balanceados. Vamos a evaluarlo en las predicciones para el conjunto de datos \"nueve vs. resto\" que calculamos anteriormente. Aquí, asumiremos que la clase \"nueve\" es la clase positiva (está etiquetada como Verdadera mientras que el resto está etiquetada como Falsa), por lo que la clase positiva es la clase minoritaria\n",
        "\n",
        "La **exactitud** mide que tan bien realiza la predicción correcta un clasificador. Este valor corresponde a la razón entre el número de predicciones correctas respecto al número total de predicciones:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Accuracy/Exactitud} = \\frac{TP+TN}{TP+FP+TN+FN}\n",
        "\\end{equation}\n",
        "\n",
        "En la siguiente matriz se resumen varias posibles métricas derivadas de la matriz de confusión, ver [enlace](https://en.wikipedia.org/wiki/Confusion_matrix) para mayor información.\n",
        "\n",
        "![matriz_confusion](https://github.com/ssanchezgoe/viu_aprendizaje_supervisado/blob/main/logos/matriz_confusion_2_categorias.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b7sj84GVsnX"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"f most_frequent: {:.2f}\".format(f1_score(y_test, pred_most_frequent)))\n",
        "print(\"f dummy: {:.2f}\".format(f1_score(y_test, pred_dummy)))\n",
        "print(\"f svm: {:.2f}\".format(f1_score(y_test, pred_svm)))\n",
        "print(\"f LG: {:.2f}\".format(f1_score(y_test, pred_logreg)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbnKweaXVu7k"
      },
      "source": [
        "Podemos ver una distinción bastante fuerte entre las predicciones para dummy y para LG, que no estaba tan clara cuando se observaba solo la *accuracy*. Usando el puntaje f para la evaluación, resumimos nuevamente el rendimiento predictivo en un número. Sin embargo, el puntaje f parece capturar nuestra intuición de lo que es un buen modelo mucho mejor que la *accuracy*.\n",
        "\n",
        "Si queremos un resumen más completo de precisión, exhaustividad y puntaje f, podemos usar la función `clasificación_report` para calcular los tres a la vez"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWWuETmVzdR"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, pred_most_frequent,\n",
        "                            target_names=[\"not nine\", \"nine\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c4ypiIqV1xo"
      },
      "source": [
        "La función `clasificación_report` produce una línea por clase (aquí, Verdadero y Falso) e informa precisión, exhaustividad y puntaje f con esta clase como clase positiva. Antes, asumíamos que la clase minoritaria \"nueve\" era la clase positiva. Si cambiamos la clase positiva a \"no nueve\", podemos ver a partir del resultado del informe de clasificación que obtenemos una puntuación f de 0,94 con el modelo most_frequent. Además, para la clase \"no nueve\" tenemos una exhaustividad de 1, ya que clasificamos todas las muestras como \"no nueve\". La última columna junto al puntaje f proporciona el soporte de cada clase, lo que simplemente significa el número de muestras en esta clase.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKjL8jfWV3jZ"
      },
      "source": [
        "print(classification_report(y_test, pred_dummy,\n",
        "                            target_names=[\"not nine\", \"nine\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsWf5VlmV5Kf"
      },
      "source": [
        "print(classification_report(y_test, pred_logreg,\n",
        "                            target_names=[\"not nine\", \"nine\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NqzeeKvV8lI"
      },
      "source": [
        "Como podemos observar al mirar los informes, las diferencias entre los modelos ficticios y un modelo muy bueno ya no son tan claras. Elegir qué clase se declara la clase positiva tiene un gran impacto en las métricas. Mientras que el puntaje f para la clasificación ficticia es 0.09 (vs. 0.89 para la regresión logística) en la clase \"nueve\", para la clase \"no nueve\" es 0.90 vs. 0.99, que parecen resultados razonables. Sin embargo, al mirar todos los números juntos obtenemos una imagen bastante precisa de los resultados, y podemos ver claramente la superioridad del modelo de regresión logística"
      ]
    }
  ]
}